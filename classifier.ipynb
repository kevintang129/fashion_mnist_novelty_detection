{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "UaYe9zfFOYTe",
    "outputId": "562b5d87-76ca-4dbf-e079-79ead71aec0f"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;\n",
    "import math;\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui-bPrZ2OYTi"
   },
   "source": [
    "## Computer Vision Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2Km2Dv6OYTj"
   },
   "source": [
    "This computer vision competition is on something called \"novelty detection\", which is where the goal is being able to learn to detect novelties. In other words, you are given a training set of data, $D_{train}$, and at test time you are given $D_{test}$ which contains both data types from $D_{train}$ as well as novel data that has not been seen before. The task is that, at test time, your model will need to classify an image as a type from $D_{train}$, or something novel. This is a twist on the classification problems we have gone over in this class.\n",
    "\n",
    "For this problem, we will be using the Fashion MNIST dataset as the training data. More information about this dataset can be found here: https://github.com/zalandoresearch/fashion-mnist \n",
    "\n",
    "At test time, we will run the model you have trained on a mystery dataset that is a combination of new Fashion MNIST data and also novel data from a different dataset, and your model will be ranked by how well it is able to distinguish Fashion data from novel data.\n",
    "\n",
    "Your model can output something like a probability (hint: use Sigmoid activation function at the end) or threshold cutoff that allows you to distinguish that an image is novel, and this will be used to perform a binary classification of sorts (either novel, or not novel). **The important thing is that at the very end, your model outputs either a 0 if you think the image is of the same type as the training data, and a 1 if your model thinks it is novel**. The highest accuracy of novelty detection will win this competition. There is a lot of creativity allowed in this project, so we recommend you brainstorm some new ideas or even read up on some novelty detection literature if you are interested. All code submitted must be your own.\n",
    "\n",
    "There is some skeleton code given, but feel free to change as much or as little as you would like, as long as you train using **only** the FashionMNIST dataset. Here are a couple of ideas on how you could go about this to get you started:\n",
    "\n",
    "* Traditional image classification assigns a probability of each label to an image, perhaps do something along the lines of thresholding so that if the highest probability an image has of being a certain label is still below $x$, it is novel\n",
    "* Checking how close/far a test image is to the training images, and thresholding\n",
    "* Looking at how close certain features (for example, 2 layers into a 4 layer CNN) may be to the training data\n",
    "\n",
    "At the end of training, be sure to save your model weights (code has been provided to do so). We will test your model, and the following is what you will need to submit (please include all of the code in the provided turnin.py file):\n",
    "\n",
    "* Code that includes\n",
    "    * Model architecture\n",
    "    * Preprocessing of images (must only use a variation of the given transform function)\n",
    "    * (Optional) postprocessing, instructions on this are in the last cell\n",
    "* Model weights in the form of a 'pth' file\n",
    "* Brief writeup giving a high-level overview of what you implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8_1THZKOYTj"
   },
   "outputs": [],
   "source": [
    "# feel free to change how much or little preprocessing is done, and at test \n",
    "# time the same preprocessing will be done on the test data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSlEVDznOYTl"
   },
   "outputs": [],
   "source": [
    "# Sample model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.sigmoid(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "net = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyH_jxCyOYTo"
   },
   "outputs": [],
   "source": [
    "# Sample hyperparameters\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ko5I8NSSOYTq"
   },
   "outputs": [],
   "source": [
    "# Sample loss functions and optimizers\n",
    "# criterion = F.nll_loss # BCELoss if output is sigmoid is recommended\n",
    "\n",
    "criterion = nn.L1Loss() # BCELoss if output is sigmoid is recommended\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "AoTG85QbOYTt",
    "outputId": "2e65d63f-7921-4872-f267-4fedf1c386e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevintang/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or more dimensions (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f542e7d6a832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         print(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or more dimensions (got 1)"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "number = len(train_loader)\n",
    "for epoch in range(epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "#         print (labels)\n",
    "        outputs = outputs#.squeeze().float()\n",
    "        _, outputs = torch.max(outputs,1)#[1]\n",
    "        \n",
    "        outputs = outputs.float()\n",
    "#         print(outputs.shape)\n",
    "        outputs.requires_grad = True\n",
    "#         print(outputs)\n",
    "\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i == (number - 10):\n",
    "            loss = running_loss / (number - 10)\n",
    "            print(\"Epoch: {0}, Loss: {1}\".format(epoch + 1, loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "directory = './saved_model/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "torch.save(net.state_dict(), './saved_model/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSTwAjF6OYTw"
   },
   "source": [
    "To make sure your code is written in a way that is compatible with our testing framework, please make sure that the following code below runs. It also has the benefit of showing you how well your model does at classifying images from the training distribution correctly. It does **not** contain any of the novel images your model will eventually be tested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "YAc2Hdx2OYTw",
    "outputId": "024c437d-e0d3-4582-e07a-6cf8257b0bca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevintang/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5069.]\n",
      "[10000.]\n",
      "[0.5069] 1\n",
      "Accuracy for test in distribution data: 0.5069\n"
     ]
    }
   ],
   "source": [
    "# Check that code works\n",
    "\n",
    "net = CNN()\n",
    "net.load_state_dict(torch.load('./saved_model/model.pth'))\n",
    "net.eval()\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "corrects = np.zeros(1)\n",
    "totals = np.zeros(1)\n",
    "with torch.no_grad():\n",
    "    for j, loader in enumerate([test_loader]):\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            labels = torch.zeros_like(labels) + j\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # If needed, can add a line here that thresholds, or does something with the\n",
    "            # 'outputs' variable to get it into a compatible format. An example is something\n",
    "            # like _, outputs = torch.max(outputs.data, 1). If this line is needed, please\n",
    "            # this along with your model architecture code labeled as 'postprocess'\n",
    "            outputs = outputs.squeeze().float()\n",
    "            prob, outputs = torch.max(outputs,1)#[1]\n",
    "            maxi = torch.max(prob)\n",
    "            mini = torch.min(prob)\n",
    "            prob = torch.add(prob, mini*-1)\n",
    "            prob = torch.div(prob, maxi-mini)\n",
    "            y = torch.ones(prob.shape)\n",
    "            z = torch.zeros(prob.shape)\n",
    "            outputs = torch.where(prob <= .4, y, z)\n",
    "#             outputs = torch.where(prob >= 0.1284, prob, z)\n",
    "#             print(outputs)\n",
    "            corrects[j] += (outputs == labels.float()).sum().item()\n",
    "            totals[j] += (labels.size(0))\n",
    "            \n",
    "print(corrects)\n",
    "print(totals)\n",
    "accs = corrects / totals\n",
    "print(accs, len(accs))\n",
    "print(\"Accuracy for test in distribution data: {0}\".format(accs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwJsnEQAOYTz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGnhmasyOYT2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "starter_code.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
